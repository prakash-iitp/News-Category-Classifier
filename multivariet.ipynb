{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z0BgCQ2KQ7v"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO5_9cZUPHO4",
        "outputId": "6f21fc05-ee13-47dd-8ea3-913175104da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKQ-J4OFkgBF",
        "outputId": "c8e90b01-8bde-42a0-8d9e-78e15b439687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/resume/dataset.json',lines=True)"
      ],
      "metadata": {
        "id": "03rW5mDPPZdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df[df['category'].isin(['COMEDY','BUSINESS', 'SPORTS', 'CRIME','RELIGION','HEALTHY LIVING', 'POLITICS'])]\n",
        "filtered_df_shuffle = filtered_df.sample(frac=1,random_state=42)\n",
        "\n",
        "total_rows = len(filtered_df_shuffle)\n",
        "train_rows = int(0.85*total_rows)\n",
        "test_rows = total_rows-train_rows\n",
        "\n",
        "train_df = filtered_df_shuffle.iloc[:train_rows, :]\n",
        "test_df = filtered_df_shuffle.iloc[train_rows:, :]"
      ],
      "metadata": {
        "id": "e8mzGbzhvvsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniq_categ = train_df['category'].value_counts()\n",
        "total =0\n",
        "for i in range(0,len(uniq_categ)):\n",
        "  total+=uniq_categ[i]\n",
        "\n",
        "total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyYCLJRjlwWr",
        "outputId": "463ed9c8-5a48-40cb-b100-297d04aa11c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48682"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uniq_cat = test_df['category'].value_counts()\n",
        "total_test =0\n",
        "for i in range(0,len(uniq_cat)):\n",
        "  total_test+=uniq_cat[i]\n",
        "\n",
        "total_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6y7mO9CrHdY",
        "outputId": "51c1116e-11ad-4c53-da21-61e48319d256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8592"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prior = {}\n",
        "for category,count in uniq_categ.items():\n",
        "  prob = count/total\n",
        "  prior[category] = {'count':count,'prob': prob}\n",
        "\n",
        "for category in uniq_categ.items():\n",
        "  print(category[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLtVtA1ko4Bt",
        "outputId": "bf8a0726-40bb-4ca0-b3ba-7e34ace9c28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POLITICS\n",
            "HEALTHY LIVING\n",
            "BUSINESS\n",
            "SPORTS\n",
            "COMEDY\n",
            "CRIME\n",
            "RELIGION\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prior_test = {}\n",
        "for category,count in uniq_cat.items():\n",
        "  prob = count/total_test\n",
        "  prior_test[category] = {'count':count,'prob': prob}\n",
        "\n",
        "for category in uniq_cat.items():\n",
        "  print(category[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jNsG_tuP-2J",
        "outputId": "3160a0d7-b704-43d1-90ea-60c6d873dc13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POLITICS\n",
            "HEALTHY LIVING\n",
            "COMEDY\n",
            "BUSINESS\n",
            "SPORTS\n",
            "CRIME\n",
            "RELIGION\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_desc = ' '.join(train_df['short_description'])\n",
        "all_words = re.findall(r'\\b\\w+\\b',all_desc.lower())\n",
        "categ_word_count = {}\n",
        "unique_words_count = {}\n",
        "unique_words_category = {}\n",
        "filtered= []\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "for category in train_df['category'].unique():\n",
        "  category_df = train_df[train_df['category']==category]\n",
        "  category_word = []\n",
        "  for i in range(0,len(category_df)):\n",
        "    string = category_df.iloc[i]['short_description']\n",
        "    string1 = re.findall(r'\\b\\w+\\b',string.lower())\n",
        "    string2 = word_tokenize(string.lower())\n",
        "    string3 = set(string2)\n",
        "    string4 = list(string3)\n",
        "    content_word = [word for word in string4 if word.isalpha() and word not in stop_words]\n",
        "    category_word += content_word\n",
        "  unique_words = set(category_word)\n",
        "  unique_words_category[category]=unique_words\n",
        "  filtered = category_word\n",
        "  word_freq = FreqDist(category_word)\n",
        "  categ_word_count[category] = word_freq\n",
        "  unique_words_count[category] = len(unique_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSklXftS3M3G",
        "outputId": "75dc1ea3-707a-43e1-c37e-dfcc86e03d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prior['POLITICS']['count'])\n",
        "print(prior_test['POLITICS']['count'])"
      ],
      "metadata": {
        "id": "Jz7pzwtmrn0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab571b4a-b752-4fa6-b373-daeec22c994a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27849\n",
            "4890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "correct =0\n",
        "category_count={}\n",
        "category_correct={}\n",
        "for category in uniq_categ.items():\n",
        "  category_count[category[0]] = 0  # Initialize the count for each category\n",
        "  category_correct[category[0]] = 0  # Initialize the correct prediction count for each category\n",
        "for i in range(0,len(test_df)):\n",
        "  #print(test_df.iloc[i])\n",
        "  string = test_df.iloc[i]['short_description']\n",
        "  cat = test_df.iloc[i]['category']\n",
        "  words1 = re.findall(r'\\b\\w+\\b',string.lower())\n",
        "  words = word_tokenize(string.lower())\n",
        "  word = set(words)\n",
        "  string4 = list(word)\n",
        "  content_word = [word for word in string4 if word.isalpha() and word not in stop_words]\n",
        "  res_prob={}\n",
        "  for category in uniq_categ.items():\n",
        "    group_prob=np.log(prior[category[0]]['prob'])\n",
        "    for w in content_word:\n",
        "      word_count = categ_word_count[category[0]][w]\n",
        "      res = np.log((1+word_count))-np.log((2+prior[category[0]]['count']))\n",
        "      group_prob+=res\n",
        "\n",
        "    res_prob[category[0]]= group_prob\n",
        "\n",
        "  #print(res_prob)\n",
        "  max_categ = max(res_prob,key=res_prob.get)\n",
        "  category_count[category[0]]+=1\n",
        "  # print(max_categ)\n",
        "  if cat==max_categ:\n",
        "    category_correct[max_categ]+=1\n",
        "    correct+=1\n",
        "  #print(\"predicted: \",max_categ)\n",
        "  #print(\"---------------------------------------\")\n",
        "for category in uniq_categ.items():\n",
        "  print(category[0],\" = \",((category_correct[category[0]])/(prior_test[category[0]]['count']))*100)\n",
        "print(((correct)/len(test_df))*100)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgoR3vMO7LaE",
        "outputId": "ee618327-1372-4a7c-e6ec-03290e32de43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POLITICS  =  62.78118609406953\n",
            "HEALTHY LIVING  =  47.72065955383123\n",
            "BUSINESS  =  59.45945945945946\n",
            "SPORTS  =  34.455128205128204\n",
            "COMEDY  =  9.404388714733543\n",
            "CRIME  =  48.33759590792839\n",
            "RELIGION  =  52.44215938303341\n",
            "53.58472998137802\n"
          ]
        }
      ]
    }
  ]
}